# Exploring and Cleaning Toward a Silver Layer

**Here is what you will learn as part of this chapter:**

1. Exploring data with the Databricks Assistant
2. Generating data profiles with AutoML
3. Visualizing data with DBSQL
4. Setting data quality expectations with DLT

## Technical requirements 

**Here are the technical requirements needed to complete the hands-on examples in this chapter:**
1. 1. The [Databricks Assistant](https://docs.databricks.com/en/notebooks/notebook-assistant-faq.html) is a newer feature that an administrator can enable. We will show the Assistant in this chapter.
2. 2. We use the [missingno](https://pypi.org/project/missingno/) library to address missing numbers in our project data. 
3. In the section using AutoML, we reference the [AutoML-generated notebook](https://github.com/PacktPublishing/Databricks-Lakehouse-ML-In-Action/blob/0dbe21cdd3e11ff9295048d4d07bec14d037150e/Chapter_4_Cleaning_and_exploring/Favorita%20Forecasting%20Exploration/Autogenerated%20Data%20Exploration%20Notebook.py), which you can find in the GitHub repository. 

## Links

**In the chapter:**
1. [ydata-profiling](https://ydata-profiling.ydata.ai/docs/master/index.html)
2. [Google MediaPipe Libary](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker#:~:text=The%20MediaPipe%20Hand%20Landmarker%20task,visual%20effects%20over%20the%20hands.)

**Further Reading:**
-[Enabling visualizations with Aggregations in DBSQL](https://docs.databricks.com/sql/user/visualizations/index.html#enable-aggregation-in-a-visualization)
-[Using the ydata profiler to explore data](https://ydata-profiling.ydata.ai/docs/master/index.html)
-[Advancing Spark - Meet the new Databricks Assistant](https://youtu.be/Tv8D72oI0xM)
-[Introducing the new Databricks Assistant](https://www.databricks.com/blog/introducing-databricks-assistant)
